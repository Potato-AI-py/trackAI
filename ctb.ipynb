{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-10T13:45:53.097578Z",
     "iopub.status.busy": "2023-03-10T13:45:53.096476Z",
     "iopub.status.idle": "2023-03-10T13:45:53.879567Z",
     "shell.execute_reply": "2023-03-10T13:45:53.877396Z",
     "shell.execute_reply.started": "2023-03-10T13:45:53.097530Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "start_time": "2023-03-22T01:43:04.148758Z",
     "end_time": "2023-03-22T01:43:04.337233Z"
    }
   },
   "outputs": [],
   "source": [
    "KAGGLE = False\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "import catboost as ctb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-03-22T01:43:04.158747Z",
     "end_time": "2023-03-22T01:43:04.353165Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-10T13:45:53.887735Z",
     "iopub.status.busy": "2023-03-10T13:45:53.887208Z",
     "iopub.status.idle": "2023-03-10T13:45:55.077345Z",
     "shell.execute_reply": "2023-03-10T13:45:55.075607Z",
     "shell.execute_reply.started": "2023-03-10T13:45:53.887685Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "start_time": "2023-03-22T01:43:04.196108Z",
     "end_time": "2023-03-22T01:43:04.362145Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "DATA_PATH = ''\n",
    "\n",
    "\n",
    "SEED = 2024\n",
    "cat_feats = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-03-22T01:43:04.228024Z",
     "end_time": "2023-03-22T01:43:13.599302Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data: (791616, 77)\n",
      "test_data: (216384, 74)\n",
      "all: (1008000, 80)\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_parquet(os.path.join(DATA_PATH, 'track3_train.parquet'))\n",
    "test_data = pd.read_parquet(os.path.join(DATA_PATH, 'track3_a.parquet'))\n",
    "\n",
    "train_data['type'] = 'train'\n",
    "test_data['type'] = 'test'\n",
    "data = pd.concat([train_data, test_data], axis=0).reset_index(drop=True)\n",
    "data = pd.concat([data, data['ID'].str.split('_', expand=True).rename(columns={0:'station',1:'sample',2:'time'})], axis=1)#细化向关联项\n",
    "\n",
    "print(f'train_data: {train_data.shape}')\n",
    "print(f'test_data: {test_data.shape}')\n",
    "print(f'all: {data.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-03-22T01:43:13.607806Z",
     "end_time": "2023-03-22T01:43:13.656684Z"
    }
   },
   "outputs": [],
   "source": [
    "TARGET_FEATS = ['wdir_2min', 'spd_2min', 'spd_inst_max']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-03-22T01:43:13.617792Z",
     "end_time": "2023-03-22T01:43:13.689595Z"
    }
   },
   "outputs": [],
   "source": [
    "# 删除有问题的目标\n",
    "for item in TARGET_FEATS:\n",
    "    idx = data[item] >= 199999.0\n",
    "    data.loc[idx, item] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-03-22T01:43:13.669649Z",
     "end_time": "2023-03-22T01:43:16.036252Z"
    }
   },
   "outputs": [],
   "source": [
    "data['station'] = data['station'].apply(lambda x: int(x.split('D')[-1]))\n",
    "cat_feats += ['station']\n",
    "\n",
    "data['sample'] = data['sample'].apply(lambda x: int(x.split('Sample')[-1]))\n",
    "data['time'] = data['time'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-03-22T01:43:16.044223Z",
     "end_time": "2023-03-22T01:43:16.052200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feats: 74, ['100u', '100v', '10u', '10v', '2d', '2t', 'cape', 'capes', 'cp', 'deg0l', 'lcc', 'msl', 'skt', 'sp', 'sst', 'tcc', 'd_L1000', 'q_L1000', 'r_L1000', 't_L1000', 'u_L1000', 'v_L1000', 'w_L1000', 'd_L950', 'q_L950', 'r_L950', 't_L950', 'u_L950', 'v_L950', 'w_L950', 'd_L925', 'q_L925', 'r_L925', 't_L925', 'u_L925', 'v_L925', 'w_L925', 'd_L900', 'q_L900', 'r_L900', 't_L900', 'u_L900', 'v_L900', 'w_L900', 'd_L850', 'q_L850', 'r_L850', 't_L850', 'u_L850', 'v_L850', 'w_L850', 'd_L700', 'q_L700', 'r_L700', 't_L700', 'u_L700', 'v_L700', 'w_L700', 'd_L500', 'q_L500', 'r_L500', 't_L500', 'u_L500', 'v_L500', 'w_L500', 'd_L200', 'q_L200', 'r_L200', 't_L200', 'u_L200', 'v_L200', 'w_L200', 'station', 'time']\n",
      "['station']\n"
     ]
    }
   ],
   "source": [
    "feats = [item for item in data.columns if item not in TARGET_FEATS+['ID', 'sample', 'type']]#剔除不相关项\n",
    "print(f'feats: {len(feats)}, {feats}')\n",
    "print(cat_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "outputs": [
    {
     "data": {
      "text/plain": "                           ID  wdir_2min  spd_2min  spd_inst_max      100u  \\\n0        D0011_Sample00000_01       88.0       4.5           5.2 -3.178867   \n1        D0011_Sample00000_02      101.0       4.5           6.0 -3.044837   \n2        D0011_Sample00000_03      111.0       3.9           5.1 -2.910807   \n3        D0011_Sample00000_04      160.0       1.7           4.3 -1.870547   \n4        D0011_Sample00000_05      179.0       1.3           2.9 -0.830286   \n...                       ...        ...       ...           ...       ...   \n1007995  D0009_Sample02128_44        NaN       NaN           NaN  3.843052   \n1007996  D0009_Sample02128_45        NaN       NaN           NaN  3.674979   \n1007997  D0009_Sample02128_46        NaN       NaN           NaN  4.163034   \n1007998  D0009_Sample02128_47        NaN       NaN           NaN  4.651088   \n1007999  D0009_Sample02128_48        NaN       NaN           NaN  5.139143   \n\n             100v       10u       10v        2d        2t  ...    q_L200  \\\n0        1.520631 -3.035558  0.921220 -4.296475  2.166330  ...  0.005066   \n1        1.737420 -2.924957  1.208521 -3.802847  2.137752  ...  0.005006   \n2        1.954209 -2.814357  1.495822 -3.309219  2.109175  ...  0.004946   \n3        1.442103 -1.843161  1.229792 -3.500122  1.850405  ...  0.004919   \n4        0.929998 -0.871964  0.963762 -3.691025  1.591636  ...  0.004893   \n...           ...       ...       ...       ...       ...  ...       ...   \n1007995  8.813500  3.456899  8.086399 -6.134135  4.715720  ...  0.005002   \n1007996  9.288052  3.270604  8.504519 -6.362700  5.081217  ...  0.005217   \n1007997  9.299423  3.684067  8.492985 -5.268479  5.118454  ...  0.005117   \n1007998  9.310794  4.097529  8.481452 -4.174258  5.155692  ...  0.005016   \n1007999  9.322165  4.510991  8.469918 -3.080037  5.192929  ...  0.004915   \n\n           r_L200     t_L200     u_L200    v_L200    w_L200   type  station  \\\n0        7.282292 -54.574743  60.027509  4.458829  0.052047  train       11   \n1        6.950891 -54.490239  58.961815  3.799950  0.053916  train       11   \n2        6.619490 -54.405734  57.896121  3.141070  0.055785  train       11   \n3        6.931894 -54.718634  57.157805  2.129127  0.064269  train       11   \n4        7.244298 -55.031533  56.419490  1.117184  0.072752  train       11   \n...           ...        ...        ...       ...       ...    ...      ...   \n1007995  7.706795 -54.882592  58.070532 -1.666188  0.017625   test        9   \n1007996  8.115371 -54.979291  58.097675 -2.525959 -0.009414   test        9   \n1007997  7.934781 -54.952597  58.558392 -3.415087  0.020155   test        9   \n1007998  7.754191 -54.925903  59.019110 -4.304215  0.049725   test        9   \n1007999  7.573601 -54.899210  59.479827 -5.193343  0.079294   test        9   \n\n         sample  time  \n0             0     1  \n1             0     2  \n2             0     3  \n3             0     4  \n4             0     5  \n...         ...   ...  \n1007995    2128    44  \n1007996    2128    45  \n1007997    2128    46  \n1007998    2128    47  \n1007999    2128    48  \n\n[1008000 rows x 80 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>wdir_2min</th>\n      <th>spd_2min</th>\n      <th>spd_inst_max</th>\n      <th>100u</th>\n      <th>100v</th>\n      <th>10u</th>\n      <th>10v</th>\n      <th>2d</th>\n      <th>2t</th>\n      <th>...</th>\n      <th>q_L200</th>\n      <th>r_L200</th>\n      <th>t_L200</th>\n      <th>u_L200</th>\n      <th>v_L200</th>\n      <th>w_L200</th>\n      <th>type</th>\n      <th>station</th>\n      <th>sample</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>D0011_Sample00000_01</td>\n      <td>88.0</td>\n      <td>4.5</td>\n      <td>5.2</td>\n      <td>-3.178867</td>\n      <td>1.520631</td>\n      <td>-3.035558</td>\n      <td>0.921220</td>\n      <td>-4.296475</td>\n      <td>2.166330</td>\n      <td>...</td>\n      <td>0.005066</td>\n      <td>7.282292</td>\n      <td>-54.574743</td>\n      <td>60.027509</td>\n      <td>4.458829</td>\n      <td>0.052047</td>\n      <td>train</td>\n      <td>11</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>D0011_Sample00000_02</td>\n      <td>101.0</td>\n      <td>4.5</td>\n      <td>6.0</td>\n      <td>-3.044837</td>\n      <td>1.737420</td>\n      <td>-2.924957</td>\n      <td>1.208521</td>\n      <td>-3.802847</td>\n      <td>2.137752</td>\n      <td>...</td>\n      <td>0.005006</td>\n      <td>6.950891</td>\n      <td>-54.490239</td>\n      <td>58.961815</td>\n      <td>3.799950</td>\n      <td>0.053916</td>\n      <td>train</td>\n      <td>11</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>D0011_Sample00000_03</td>\n      <td>111.0</td>\n      <td>3.9</td>\n      <td>5.1</td>\n      <td>-2.910807</td>\n      <td>1.954209</td>\n      <td>-2.814357</td>\n      <td>1.495822</td>\n      <td>-3.309219</td>\n      <td>2.109175</td>\n      <td>...</td>\n      <td>0.004946</td>\n      <td>6.619490</td>\n      <td>-54.405734</td>\n      <td>57.896121</td>\n      <td>3.141070</td>\n      <td>0.055785</td>\n      <td>train</td>\n      <td>11</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>D0011_Sample00000_04</td>\n      <td>160.0</td>\n      <td>1.7</td>\n      <td>4.3</td>\n      <td>-1.870547</td>\n      <td>1.442103</td>\n      <td>-1.843161</td>\n      <td>1.229792</td>\n      <td>-3.500122</td>\n      <td>1.850405</td>\n      <td>...</td>\n      <td>0.004919</td>\n      <td>6.931894</td>\n      <td>-54.718634</td>\n      <td>57.157805</td>\n      <td>2.129127</td>\n      <td>0.064269</td>\n      <td>train</td>\n      <td>11</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>D0011_Sample00000_05</td>\n      <td>179.0</td>\n      <td>1.3</td>\n      <td>2.9</td>\n      <td>-0.830286</td>\n      <td>0.929998</td>\n      <td>-0.871964</td>\n      <td>0.963762</td>\n      <td>-3.691025</td>\n      <td>1.591636</td>\n      <td>...</td>\n      <td>0.004893</td>\n      <td>7.244298</td>\n      <td>-55.031533</td>\n      <td>56.419490</td>\n      <td>1.117184</td>\n      <td>0.072752</td>\n      <td>train</td>\n      <td>11</td>\n      <td>0</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1007995</th>\n      <td>D0009_Sample02128_44</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3.843052</td>\n      <td>8.813500</td>\n      <td>3.456899</td>\n      <td>8.086399</td>\n      <td>-6.134135</td>\n      <td>4.715720</td>\n      <td>...</td>\n      <td>0.005002</td>\n      <td>7.706795</td>\n      <td>-54.882592</td>\n      <td>58.070532</td>\n      <td>-1.666188</td>\n      <td>0.017625</td>\n      <td>test</td>\n      <td>9</td>\n      <td>2128</td>\n      <td>44</td>\n    </tr>\n    <tr>\n      <th>1007996</th>\n      <td>D0009_Sample02128_45</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3.674979</td>\n      <td>9.288052</td>\n      <td>3.270604</td>\n      <td>8.504519</td>\n      <td>-6.362700</td>\n      <td>5.081217</td>\n      <td>...</td>\n      <td>0.005217</td>\n      <td>8.115371</td>\n      <td>-54.979291</td>\n      <td>58.097675</td>\n      <td>-2.525959</td>\n      <td>-0.009414</td>\n      <td>test</td>\n      <td>9</td>\n      <td>2128</td>\n      <td>45</td>\n    </tr>\n    <tr>\n      <th>1007997</th>\n      <td>D0009_Sample02128_46</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4.163034</td>\n      <td>9.299423</td>\n      <td>3.684067</td>\n      <td>8.492985</td>\n      <td>-5.268479</td>\n      <td>5.118454</td>\n      <td>...</td>\n      <td>0.005117</td>\n      <td>7.934781</td>\n      <td>-54.952597</td>\n      <td>58.558392</td>\n      <td>-3.415087</td>\n      <td>0.020155</td>\n      <td>test</td>\n      <td>9</td>\n      <td>2128</td>\n      <td>46</td>\n    </tr>\n    <tr>\n      <th>1007998</th>\n      <td>D0009_Sample02128_47</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4.651088</td>\n      <td>9.310794</td>\n      <td>4.097529</td>\n      <td>8.481452</td>\n      <td>-4.174258</td>\n      <td>5.155692</td>\n      <td>...</td>\n      <td>0.005016</td>\n      <td>7.754191</td>\n      <td>-54.925903</td>\n      <td>59.019110</td>\n      <td>-4.304215</td>\n      <td>0.049725</td>\n      <td>test</td>\n      <td>9</td>\n      <td>2128</td>\n      <td>47</td>\n    </tr>\n    <tr>\n      <th>1007999</th>\n      <td>D0009_Sample02128_48</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.139143</td>\n      <td>9.322165</td>\n      <td>4.510991</td>\n      <td>8.469918</td>\n      <td>-3.080037</td>\n      <td>5.192929</td>\n      <td>...</td>\n      <td>0.004915</td>\n      <td>7.573601</td>\n      <td>-54.899210</td>\n      <td>59.479827</td>\n      <td>-5.193343</td>\n      <td>0.079294</td>\n      <td>test</td>\n      <td>9</td>\n      <td>2128</td>\n      <td>48</td>\n    </tr>\n  </tbody>\n</table>\n<p>1008000 rows × 80 columns</p>\n</div>"
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-03-22T01:43:16.059186Z",
     "end_time": "2023-03-22T01:43:16.615735Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-03-22T01:43:16.622233Z",
     "end_time": "2023-03-22T01:43:17.994647Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = data.query('type==\"train\"').reset_index(drop=True)\n",
    "test_data = data.query('type==\"test\"').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "trusted": true,
    "ExecuteTime": {
     "start_time": "2023-03-22T01:43:18.000611Z",
     "end_time": "2023-03-22T01:43:18.011587Z"
    }
   },
   "outputs": [],
   "source": [
    "# xgb_params = {\n",
    "#     'booster': 'gbtree', #gbtree和gblinear。gbtree是采用树的结构来运行数据，而gblinear是基于线性模型\n",
    "#     'objective': 'reg:squarederror',\n",
    "#     'eval_metric': 'mae', #rmse均方根误差 quantile分位数损失函数是一种用于回归问题的损失函数 #mae绝对值差\n",
    "#     'eta': 0.05, #学习速率 默认0.3\n",
    "#     'subsample': 0.8, #默认1，取值0-1  在不进行重采样的情况下随机选择部分数据 样本抽样\n",
    "#     'colsample_bytree': 0.8, #默认1 特征抽样\n",
    "#     'alpha': 0.1, #L1正则化\n",
    "#     'lambda': 0.1, #L2正则化\n",
    "#     'seed': SEED,\n",
    "#     'nthread': -1, #使用线程数 -1,使用所有线程\n",
    "#     'tree_method': 'gpu_hist',#GPU加速\n",
    "# }\n",
    "\n",
    "# ctb_params = {\n",
    "#     'loss_function': 'Quantile',\n",
    "#     'learning_rate': 0.01,\n",
    "#     'num_boost_round':100,\n",
    "#     'depth': 6,\n",
    "#     'l2_leaf_reg': 3,\n",
    "#     'bootstrap_type': 'Bernoulli',\n",
    "#     'subsample': 0.7,\n",
    "#     'scale_pos_weight': 1,\n",
    "#     'eval_metric': 'Quantile',\n",
    "#     'random_seed': SEED,\n",
    "#     'task_type': 'CPU',\n",
    "#     'thread_count': -1,\n",
    "#     'verbose': 100,\n",
    "#     'early_stopping_rounds':100,\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-03-22T01:43:18.015579Z",
     "end_time": "2023-03-22T01:43:18.055047Z"
    }
   },
   "outputs": [],
   "source": [
    "# 逐小时预报采用四舍五入保留1位小数位\n",
    "# 24小时内最大风由保留1位小数位的逐小时平均风速求最大值\n",
    "# 24小时内极大风由保留1位小数位的逐小时极大风速求最大值\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-03-22T01:43:18.031120Z",
     "end_time": "2023-03-22T01:43:18.055047Z"
    }
   },
   "outputs": [],
   "source": [
    "# task_name = \"ctb\"\n",
    "# task_params = {\"ctb\": ctb_params}[task_name] # 用于控制模型训练的超参数字典，如学习率、树的深度、子采样比例等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(770742, 74) (216384, 74)\n",
      "----------- 0\n"
     ]
    },
    {
     "ename": "CatBoostError",
     "evalue": "Length of label=154264 and length of data=616478 is different.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mCatBoostError\u001B[0m                             Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[281], line 71\u001B[0m\n\u001B[1;32m     28\u001B[0m \u001B[38;5;66;03m# le = LabelEncoder()\u001B[39;00m\n\u001B[1;32m     29\u001B[0m \u001B[38;5;66;03m# for col in cat_feats:\u001B[39;00m\n\u001B[1;32m     30\u001B[0m \u001B[38;5;66;03m#     train_x.loc[train_idx][col] = le.fit_transform(train_x.loc[train_idx][col])\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;66;03m# model = ctb.train(ctb_params, train,# num_boost_round=100,verbose=10,early_stopping_rounds=10,eval_set=val\u001B[39;00m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;66;03m#                  )\u001B[39;00m\n\u001B[1;32m     70\u001B[0m train_data \u001B[38;5;241m=\u001B[39m ctb\u001B[38;5;241m.\u001B[39mPool(data\u001B[38;5;241m=\u001B[39mtrain_x\u001B[38;5;241m.\u001B[39mloc[train_idx], label\u001B[38;5;241m=\u001B[39mtrain_y\u001B[38;5;241m.\u001B[39mloc[train_idx])\n\u001B[0;32m---> 71\u001B[0m test_data \u001B[38;5;241m=\u001B[39m \u001B[43mctb\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mPool\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_x\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloc\u001B[49m\u001B[43m[\u001B[49m\u001B[43mtrain_idx\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_y\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloc\u001B[49m\u001B[43m[\u001B[49m\u001B[43mval_idx\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     73\u001B[0m params \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m     74\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124miterations\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m100\u001B[39m,\n\u001B[1;32m     75\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlearning_rate\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m0.1\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     80\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlogging_level\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSilent\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m     81\u001B[0m }\n\u001B[1;32m     83\u001B[0m model \u001B[38;5;241m=\u001B[39m ctb\u001B[38;5;241m.\u001B[39mtrain(\n\u001B[1;32m     84\u001B[0m     params\u001B[38;5;241m=\u001B[39mparams,\n\u001B[1;32m     85\u001B[0m     pool\u001B[38;5;241m=\u001B[39mtrain_data,\n\u001B[1;32m     86\u001B[0m     eval_set\u001B[38;5;241m=\u001B[39mtest_data,\n\u001B[1;32m     87\u001B[0m     verbose_eval\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m     88\u001B[0m )\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/catboost/core.py:792\u001B[0m, in \u001B[0;36mPool.__init__\u001B[0;34m(self, data, label, cat_features, text_features, embedding_features, embedding_features_data, column_description, pairs, delimiter, has_header, ignore_csv_quoting, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count, log_cout, log_cerr)\u001B[0m\n\u001B[1;32m    786\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(feature_names, PATH_TYPES):\n\u001B[1;32m    787\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m CatBoostError(\n\u001B[1;32m    788\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfeature_names must be None or have non-string type when the pool is created from \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    789\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpython objects.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    790\u001B[0m             )\n\u001B[0;32m--> 792\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_init\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcat_features\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtext_features\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43membedding_features\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43membedding_features_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpairs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    793\u001B[0m \u001B[43m                   \u001B[49m\u001B[43mgroup_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroup_weight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msubgroup_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpairs_weight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbaseline\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimestamp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeature_names\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeature_tags\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mthread_count\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    794\u001B[0m \u001B[38;5;28msuper\u001B[39m(Pool, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m()\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/catboost/core.py:1367\u001B[0m, in \u001B[0;36mPool._init\u001B[0;34m(self, data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count)\u001B[0m\n\u001B[1;32m   1365\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(np\u001B[38;5;241m.\u001B[39mshape(label)) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   1366\u001B[0m         label \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mexpand_dims(label, \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m-> 1367\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_check_label_shape\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlabel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msamples_count\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1368\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m feature_names \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1369\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_feature_names(feature_names, features_count)\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/catboost/core.py:908\u001B[0m, in \u001B[0;36mPool._check_label_shape\u001B[0;34m(self, label, samples_count)\u001B[0m\n\u001B[1;32m    904\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    905\u001B[0m \u001B[38;5;124;03mCheck label length and dimension.\u001B[39;00m\n\u001B[1;32m    906\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    907\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(label) \u001B[38;5;241m!=\u001B[39m samples_count:\n\u001B[0;32m--> 908\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CatBoostError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLength of label=\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m and length of data=\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m is different.\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;28mlen\u001B[39m(label), samples_count))\n",
      "\u001B[0;31mCatBoostError\u001B[0m: Length of label=154264 and length of data=616478 is different."
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "train_oof = {}\n",
    "test_pred = {}\n",
    "feats_importance = {}\n",
    "\n",
    "for item_target in TARGET_FEATS:\n",
    "    train_y = train_data[item_target]\n",
    "    idx = ~train_y.isna()\n",
    "\n",
    "    trian_id = train_data.loc[idx, 'ID'].reset_index(drop=True)  #原始训练集中ID列+为缺失值的结果列\n",
    "    train_x = train_data.loc[idx, feats].reset_index(drop=True)  #训练集（已细化并剔除不相关）+为缺失值的结果列\n",
    "    testA_x = test_data[feats].reset_index(drop=True) #测试集（已细化并剔除不相关）\n",
    "    train_y = train_y.loc[idx].reset_index(drop=True) #缺失值的结果列\n",
    "    group_x = train_data.loc[idx, 'sample'].reset_index(drop=True) #原始训练集中sample列+为缺失值的结果列\n",
    "    print(train_x.shape, testA_x.shape)\n",
    "\n",
    "    item_oof = np.zeros(train_x.shape[0])\n",
    "    item_pred = np.zeros(testA_x.shape[0])\n",
    "\n",
    "    fold_num = 5\n",
    "    item_importance = 0\n",
    "    from sklearn.model_selection import GroupKFold #用于分组数据的交叉验证迭代器 测试模型的泛化能力 检测过拟合情况\n",
    "    kf = GroupKFold(n_splits=fold_num, ) #n_splits一般3-10之间  数据集越大n_splits调小  越大越精准但泛化能力下降过拟合增大   需要找平衡点\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(train_x, groups=group_x)): #基于GroupKFold交叉验证分组，根据sample标识（文件夹）分组  保证每个分组样本均匀分配到不同训练集和验证集中\n",
    "        print('-----------', fold)\n",
    "\n",
    "        # le = LabelEncoder()\n",
    "        # for col in cat_feats:\n",
    "        #     train_x.loc[train_idx][col] = le.fit_transform(train_x.loc[train_idx][col])\n",
    "        #     train_x.loc[val_idx][col] = le.transform(train_x.loc[val_idx][col])\n",
    "\n",
    "        # train = xgb.DMatrix(train_x.loc[train_idx], label=train_y.loc[train_idx])\n",
    "        # val = xgb.DMatrix(train_x.loc[val_idx], label=train_y.loc[val_idx])\n",
    "        # watchlist = [(train, 'train'), (val, 'val')]\n",
    "\n",
    "        # train = ctb.Pool(   # 数据集封装成一个对象、加载入内存 方便LightGBM 进行训练和预测\n",
    "        #     train_x.loc[train_idx], #训练集\n",
    "        #     train_y.loc[train_idx],\n",
    "        #     cat_features=cat_feats # 类别特征列表，用于指定数据集中哪些特征是类别型的特征\n",
    "        # )\n",
    "        # val = ctb.Pool(\n",
    "        #     train_x.loc[val_idx], #验证集\n",
    "        #     train_y.loc[val_idx],\n",
    "        #     cat_features=cat_feats # cat_feats=['station']\n",
    "        # )\n",
    "\n",
    "        # ctb_pa\n",
    "        # model = ctb.train(ctb_params, train,# num_boost_round=100,verbose=10,early_stopping_rounds=10,eval_set=val\n",
    "        #                  )\n",
    "\n",
    "\n",
    "\n",
    "        train_data = ctb.Pool(data=train_x.loc[train_idx], label=train_y.loc[train_idx])\n",
    "        test_data = ctb.Pool(data=train_x.loc[train_idx], label=train_y.loc[val_idx])\n",
    "\n",
    "        params = {\n",
    "            'iterations': 100,\n",
    "            'learning_rate': 0.1,\n",
    "            'depth': 6,\n",
    "            'loss_function': 'Logloss',\n",
    "            'eval_metric': 'AUC',\n",
    "            'random_seed': 42,\n",
    "            'logging_level': 'Silent'\n",
    "        }\n",
    "\n",
    "        model = ctb.train(\n",
    "            params=params,\n",
    "            pool=train_data,\n",
    "            eval_set=test_data,\n",
    "            verbose_eval=False\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        #valid_sets 验证数据集为什么还要加上train\n",
    "        \"\"\"\n",
    "        params: 用于控制模型训练的超参数字典，如学习率、树的深度、子采样比例等。\n",
    "        train_set: 训练数据集，可以是 lgb.Dataset 对象或数据矩阵。\n",
    "        num_boost_round: 迭代次数，即弱分类器的数量。\n",
    "        valid_sets: 验证数据集，可以是一个 lgb.Dataset 对象或一个列表，其中每个元素都是 lgb.Dataset 对象。\n",
    "        early_stopping_rounds: 早停次数，如果在连续的 early_stopping_rounds 次迭代中验证集的损失没有得到改善，则停止迭代。\n",
    "            lgb.early_stopping()比这个好用，可以把num_boost_round放的很大，他可以智能判断早停\n",
    "        callbacks: 回调函数列表，用于在训练过程中执行特定操作，如打印日志、保存模型等。\n",
    "        \"\"\"\n",
    "        item_oof[val_idx] += (model.predict(train_x.loc[val_idx])) #预测验证集结果存入item_oof\n",
    "\n",
    "        item_pred += (model.predict(testA_x))/fold_num  #预测测试集/折数=平局值 item_pred\n",
    "        # item_importance += model.feature_importance(importance_type='gain') / fold_num # 特征性/折数=平均值 importance_type=split/gain 分别表示特征被用于分裂的次数和特征对模型的贡献度\n",
    "\n",
    "    # importance = pd.DataFrame()\n",
    "    # importance['name'] = feats\n",
    "    # importance['importance'] = item_importance\n",
    "\n",
    "    train_oof[item_target] = pd.DataFrame({\"ID\": trian_id, f\"{item_target}_true\": train_y, f\"{item_target}_pred\": item_oof}) #重构预测的验证集结果列\n",
    "    test_pred[item_target] = pd.DataFrame({\"ID\": test_data['ID'], f\"{item_target}\": item_pred})\n",
    "    # feats_importance[item_target] = importance #重构预测的测试集结果列"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_oof = reduce(lambda x,y: pd.merge(x,y,on='ID', how='outer'), train_oof.values())\n",
    "test_pred = reduce(lambda x,y: pd.merge(x,y,on='ID', how='outer'), test_pred.values())\n",
    "train_oof.shape\n",
    "test_pred.shape\n",
    "\n",
    "score_str = 'potato_x'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"result\"):\n",
    "    os.makedirs(\"result\")\n",
    "train_oof.to_csv(os.path.join(\"result\", f'lgb_oof_{score_str}.csv'), index=False)\n",
    "test_pred.to_csv(os.path.join(\"result\", f'{score_str}.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.11 ('AL')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "82785e3617b41da40eac9dc72b5795aea1d455d121b27bd2aa7c1fc59bb3871c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
